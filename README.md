# EECE6083_Compiler
Compiler Project for EECE6083
David Luria
Updated: 5/5/2019

**File structure:**
* /src contains the source code of the project and /bin contains the binary to run the compiler
* Each binary includes one required argument: the location of the program to be compiled. So it should be run as such:

  ./bin_name [file location]

* You will find several versions of the compiler. As I am still working on the code generation of the compiler, 
  I have included the last stable version of the compiler, named Semantics. This will parse and evaluate the semantic rules of the 
  input file, producing the necessary errors, but will not generate any code. Semantics_Verbose will output the live status of the compiler
  to the console. This is what is to be considered "finished"
* I included CodeGen and CodeGen_Verbose as well, but these are not stable. They will generate code for some expressions, but code 
  generation is still very much a WIP, and I will update it throughout the summer. I have included it to show where I am currently in my work,
  and that I am generating code to some degree.
* Generated code is in reduced assembly-like C currently, but I may consider moving to LLVM in the future.

**Description:**
This compiler project was build in c++ using a one-pass process. The scanner is a method that simply looks through the input code and produce
"tokens". Tokens are pieces of code that represent pieces of logic that can be used to build the entire program. These are things like identifiers,
line ends, numbers, etc. Tokens are fed from the scanner to the parser. The parser makes sense of the string of tokens using grammar rules.
Grammar rules are syntactic and simply check to make sure that the code follows the structure of the source language. I have also embedded
more samantic-focused rules in the structure of the parser code. These ruels include things such as type-checking (i.e. to make sure variables
are assigned the correct type) and scoping information. The code includes symbol table management, which collect unique identifiers and phrases
and stores them in a hash table. Several symbol tables are managed, one per scope. So, when a procedure is defined, a new symbol table is created
that manages the variables of that procedure's scope. There is also a global symbol table that all scopes can access. The global table includes 
symbols that are expected to be used globally, such as "variable", "integer", "procedure", "end", etc., as well as any globally-defined variables.

The next step, which is a work in progress, is to convert the information parsed into machine code. Currently, the compiler can generate a very
small amount of code (this will be improved in the future). The code generated is currently a reduced form of C, which closely resembles assembly.
It acts like a load/store architecture, where registers are loaded with memory values, operated on, and then loaded into the appropriate
memory location. It includes management of the stack to point to the correct memory locations based on the Stack Pointer register value.
The goal of code generation is to generate C code that acts like assembly, and can be compiled separately. Alternatively, a solution using LLVM
may be investigated. In this case, LLVM intermediate representation code would be generated by the compiler to be fed to a compiler like Clang.
This may require more initial research, but will ease implementation. I am still exploring which option to go with. My current goal for the
project is to hammer out and finish code-generation. Thus, I will hopefully be able to include run-time implementaiton before the end of next term.
